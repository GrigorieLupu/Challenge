{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:51:22.047359Z",
     "start_time": "2025-03-31T13:51:22.044432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "from jupyter_server.services.config.handlers import section_name_regex\n",
    "from scipy.signal import vectorstrength\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ],
   "id": "fe3d86d79da19de8",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:51:22.640562Z",
     "start_time": "2025-03-31T13:51:22.094854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "except:\n",
    "    nlp = spacy.load('en_core_web_sm')"
   ],
   "id": "4a8cc8c185bd5a86",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:16:56.811779Z",
     "start_time": "2025-03-31T13:51:22.662777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class InsuranceTaxonomyClassifier:\n",
    "    \"\"\"\n",
    "    Clasificator care potrivește companii cu etichete din taxonomia de asigurări.\n",
    "    Utilizez tehnici NLP simple și potrivire bazată pe similaritate.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, taxonomy_path, threshold=0.15):\n",
    "        \"\"\"\n",
    "        Inițializez clasificatorul cu datele taxonomiei și pragul de potrivire.\n",
    "\n",
    "        Args:\n",
    "            taxonomy_path (str): Calea către fișierul CSV cu taxonomia\n",
    "            threshold (float): Pragul de similaritate pentru potrivire\n",
    "        \"\"\"\n",
    "        print(f\"[{self._get_timestamp()}] Inițializare clasificator...\")\n",
    "\n",
    "        self.threshold = threshold\n",
    "\n",
    "        # Încarc datele taxonomiei\n",
    "        self.taxonomy_df = pd.read_csv(taxonomy_path)\n",
    "        self.taxonomy_labels = self.taxonomy_df['label'].tolist()\n",
    "\n",
    "        # Creez mapări pentru domenii specifice\n",
    "        self.domain_mappings = self._create_domain_mappings()\n",
    "\n",
    "        # Procesez etichetele taxonomiei\n",
    "        print(f\"[{self._get_timestamp()}] Procesare {len(self.taxonomy_labels)} etichete din taxonomie...\")\n",
    "        self.processed_labels = self._preprocess_taxonomy()\n",
    "\n",
    "        # Inițializez vectorizatorul TF-IDF\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            analyzer='word',\n",
    "            min_df=2,\n",
    "            max_df=0.95,\n",
    "            ngram_range=(1, 2)  # Include unigrame și bigrame\n",
    "        )\n",
    "\n",
    "        # Pregătesc vectorizatorul cu textul din taxonomie\n",
    "        all_taxonomy_text = [' '.join(label_info['keywords']) for label_info in self.processed_labels]\n",
    "        self.vectorizer.fit(all_taxonomy_text)\n",
    "\n",
    "        # Transform etichetele taxonomiei în vectori TF-IDF\n",
    "        self.taxonomy_vectors = self.vectorizer.transform(all_taxonomy_text)\n",
    "\n",
    "        print(f\"[{self._get_timestamp()}] Clasificator inițializat cu succes!\")\n",
    "\n",
    "    def _get_timestamp(self):\n",
    "        \"\"\"Returnează timestamp-ul curent formatat.\"\"\"\n",
    "        return datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "    def _create_domain_mappings(self):\n",
    "        \"\"\"Creez mapări de cuvinte cheie specifice domeniului pentru o mai bună înțelegere a contextului.\"\"\"\n",
    "        return {\n",
    "            'construction': ['building', 'contractor', 'engineering', 'infrastructure', 'development', 'project'],\n",
    "            'healthcare': ['medical', 'health', 'clinic', 'hospital', 'patient', 'care', 'wellness', 'therapy'],\n",
    "            'agriculture': ['farm', 'crop', 'plant', 'soil', 'harvest', 'cultivation', 'field', 'livestock'],\n",
    "            'technology': ['software', 'hardware', 'it', 'computer', 'digital', 'tech', 'application', 'system'],\n",
    "            'manufacturing': ['production', 'factory', 'fabrication', 'assembly', 'industrial', 'processing'],\n",
    "            'retail': ['store', 'shop', 'sales', 'customer', 'merchandise', 'consumer', 'mall'],\n",
    "            'food': ['restaurant', 'meal', 'cuisine', 'culinary', 'catering', 'dietary', 'nutrition'],\n",
    "            'transportation': ['logistics', 'shipping', 'freight', 'delivery', 'hauling', 'trucking', 'transport'],\n",
    "            'education': ['school', 'training', 'learning', 'teaching', 'academic', 'educational', 'instruction'],\n",
    "            'finance': ['banking', 'investment', 'financial', 'money', 'fiscal', 'economic', 'accounting'],\n",
    "            'legal': ['law', 'attorney', 'legal', 'counsel', 'litigation', 'judicial', 'regulatory'],\n",
    "            'energy': ['power', 'electricity', 'gas', 'utilities', 'fuel', 'renewable', 'energy'],\n",
    "            'real_estate': ['property', 'real estate', 'leasing', 'rental', 'tenant', 'building', 'housing'],\n",
    "            'automotive': ['vehicle', 'car', 'auto', 'automotive', 'repair', 'mechanic', 'motor'],\n",
    "            'design': ['designer', 'creative', 'aesthetic', 'artistic', 'layout', 'visual'],\n",
    "            'consulting': ['advisory', 'consultant', 'guidance', 'counsel', 'strategy', 'recommendation'],\n",
    "            'media': ['publishing', 'broadcast', 'film', 'production', 'content', 'entertainment'],\n",
    "            'cosmetics': ['beauty', 'makeup', 'skincare', 'salon', 'spa', 'cosmetic'],\n",
    "            'sports': ['fitness', 'athletic', 'exercise', 'gym', 'sport', 'recreation'],\n",
    "            'maintenance': ['repair', 'upkeep', 'service', 'maintain', 'fix', 'cleaning'],\n",
    "            'animal': ['pet', 'veterinary', 'animal', 'livestock', 'fauna', 'wildlife'],\n",
    "            'security': ['protection', 'guard', 'surveillance', 'safety', 'alarm', 'monitor']\n",
    "        }\n",
    "\n",
    "    def _preprocess_text(self, text):\n",
    "        \"\"\"Procesez textul prin eliminarea caracterelor speciale, normalizare etc.\"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "\n",
    "        # Convertesc la litere mici și elimină caractere speciale\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "\n",
    "        # Elimin cuvinte comune foarte scurte\n",
    "        words = [word for word in text.split() if len(word) > 2]\n",
    "\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def _parse_business_tags(self, tags_str):\n",
    "        \"\"\"Analizez tagurile de business din reprezentarea string.\"\"\"\n",
    "        try:\n",
    "            # Înlocuiesc ghilimele simple cu duble pentru parsarea JSON\n",
    "            fixed_json = tags_str.replace(\"'\", '\"')\n",
    "            return json.loads(fixed_json)\n",
    "        except:\n",
    "            if isinstance(tags_str, str) and tags_str.startswith('[') and tags_str.endswith(']'):\n",
    "                # Extrag elementele dintre paranteze și împart după virgulă\n",
    "                items = tags_str[1:-1].split(',')\n",
    "                # Curăț fiecare element\n",
    "                return [item.strip().strip(\"'\").strip('\"') for item in items]\n",
    "            return []\n",
    "\n",
    "    def _preprocess_taxonomy(self):\n",
    "        \"\"\"Procesez etichetele taxonomiei pentru a extrage caracteristici și domenii cheie.\"\"\"\n",
    "        processed_labels = []\n",
    "\n",
    "        for label in self.taxonomy_labels:\n",
    "            # Procesare de bază a textului\n",
    "            clean_label = self._preprocess_text(label)\n",
    "\n",
    "            # Creez variație fără sufixul \"Services\"\n",
    "            without_services = re.sub(r'\\sservices$', '', clean_label)\n",
    "\n",
    "            # Extrag cuvinte\n",
    "            words = [word for word in clean_label.split() if len(word) > 2]\n",
    "\n",
    "            # Identific domeniile relevante\n",
    "            related_domains = []\n",
    "            domain_keywords = []\n",
    "\n",
    "            # Identific domeniile relevante\n",
    "            for domain, keywords in self.domain_mappings.items():\n",
    "                if any(keyword in clean_label for keyword in keywords):\n",
    "                    related_domains.append(domain)\n",
    "                    domain_keywords.extend(keywords)\n",
    "\n",
    "            # Creeaz lista de cuvinte cheie\n",
    "            keywords = words + [word for word in domain_keywords if word not in words]\n",
    "\n",
    "            # Creeaz bigrame pentru un context mai bun\n",
    "            bigrams = []\n",
    "            for i in range(len(words) - 1):\n",
    "                bigrams.append(f\"{words[i]} {words[i+1]}\")\n",
    "\n",
    "            processed_labels.append({\n",
    "                'original': label,\n",
    "                'clean_label': clean_label,\n",
    "                'without_services': without_services,\n",
    "                'words': words,\n",
    "                'bigrams': bigrams,\n",
    "                'keywords': keywords + bigrams,  # Combină pentru o reprezentare mai bogată\n",
    "                'related_domains': related_domains\n",
    "            })\n",
    "\n",
    "        return processed_labels\n",
    "\n",
    "    def _preprocess_company(self, company):\n",
    "        \"\"\"Procesez datele companiei pentru clasificare.\"\"\"\n",
    "        # Analizez tagurile de business\n",
    "        if isinstance(company['business_tags'], str):\n",
    "            business_tags = self._parse_business_tags(company['business_tags'])\n",
    "        else:\n",
    "            business_tags = []\n",
    "\n",
    "        # Curăț câmpurile de text\n",
    "        clean_description = self._preprocess_text(company['description'])\n",
    "        clean_tags = self._preprocess_text(' '.join(business_tags))\n",
    "        clean_sector = self._preprocess_text(company['sector'])\n",
    "        clean_category = self._preprocess_text(company['category'])\n",
    "        clean_niche = self._preprocess_text(company['niche'])\n",
    "\n",
    "        # Creez text combinat pentru analiză (cu ponderare câmpuri)\n",
    "        combined_text = (\n",
    "            f\"{clean_description} {clean_description} \"  # Pondere dublă pentru descriere\n",
    "            f\"{clean_tags} {clean_tags} {clean_tags} \"  # Pondere triplă pentru taguri de business\n",
    "            f\"{clean_sector} {clean_sector} \"           # Pondere dublă pentru sector\n",
    "            f\"{clean_category} {clean_category} \"       # Pondere dublă pentru categorie\n",
    "            f\"{clean_niche} {clean_niche}\"              # Pondere dublă pentru nișă\n",
    "        )\n",
    "\n",
    "        # Extrage cuvinte cheie specifice domeniului\n",
    "        domain_presence = {}\n",
    "        for domain, keywords in self.domain_mappings.items():\n",
    "            matches = sum(keyword in combined_text for keyword in keywords)\n",
    "            if matches > 0:\n",
    "                domain_presence[domain] = matches\n",
    "\n",
    "        # Creez vector de document folosind TF-IDF\n",
    "        company_vector = self.vectorizer.transform([combined_text])\n",
    "\n",
    "        return {\n",
    "            'original': company,\n",
    "            'business_tags': business_tags,\n",
    "            'clean_description': clean_description,\n",
    "            'clean_tags': clean_tags,\n",
    "            'clean_sector': clean_sector,\n",
    "            'clean_category': clean_category,\n",
    "            'clean_niche': clean_niche,\n",
    "            'combined_text': combined_text,\n",
    "            'domain_presence': domain_presence,\n",
    "            'vector': company_vector\n",
    "        }\n",
    "\n",
    "    def _score_company_for_label(self, processed_company, label_info):\n",
    "        \"\"\"\n",
    "        Calculez un scor complet de similaritate între o companie și o etichetă din taxonomie.\n",
    "        Utilizez similaritate vectorială, potriviri exacte și înțelegere de domeniu.\n",
    "        \"\"\"\n",
    "        score = 0\n",
    "\n",
    "        # Similaritate vectorială (similaritate cosinus TF-IDF)\n",
    "        vector_similarity = cosine_similarity(\n",
    "            processed_company['vector'],\n",
    "            self.vectorizer.transform([' '.join(label_info['keywords'])])\n",
    "        )[0][0]\n",
    "\n",
    "        # Scalează până la procent și adaugă la scor\n",
    "        score += vector_similarity * 50\n",
    "\n",
    "        # Verific potriviri exacte\n",
    "        clean_label = label_info['clean_label']\n",
    "        without_services = label_info['without_services']\n",
    "\n",
    "        # Verific potriviri exacte\n",
    "        if clean_label in processed_company['combined_text']:\n",
    "            score += 25\n",
    "        elif without_services != clean_label and without_services in processed_company['combined_text']:\n",
    "            score += 20\n",
    "\n",
    "        # Potrivirea tagurilor de business (pondere mai mare pentru potriviri exacte în taguri)\n",
    "        if any(clean_label in tag.lower() for tag in processed_company['business_tags']):\n",
    "            score += 20\n",
    "        elif any(without_services in tag.lower() for tag in processed_company['business_tags']):\n",
    "            score += 15\n",
    "\n",
    "        # Potrivire la nivel de cuvânt\n",
    "        for word in label_info['words']:\n",
    "            if word in processed_company['combined_text']:\n",
    "                score += 2\n",
    "\n",
    "            # Pondere extra pentru tagurile de business care conțin termeni cheie\n",
    "            if any(word in tag.lower() for tag in processed_company['business_tags']):\n",
    "                score += 3\n",
    "\n",
    "        # Potrivire bigrame (mai bună pentru context)\n",
    "        for bigram in label_info['bigrams']:\n",
    "            if bigram in processed_company['combined_text']:\n",
    "                score += 5\n",
    "\n",
    "        # Scorare de relevanță pentru domeniu\n",
    "        for domain in label_info['related_domains']:\n",
    "            if domain in processed_company['domain_presence']:\n",
    "                # Potrivire de domeniu - mai puternică dacă ambele au prezență ridicată\n",
    "                score += 2 * min(3, processed_company['domain_presence'][domain])\n",
    "\n",
    "        # Scoruri pentru potrivirea câmpurilor cheie (sector, categorie, nișă)\n",
    "        fields = {'sector': processed_company['clean_sector'],\n",
    "                 'category': processed_company['clean_category'],\n",
    "                 'niche': processed_company['clean_niche']}\n",
    "\n",
    "        for field_name, field_value in fields.items():\n",
    "            if clean_label in field_value or without_services in field_value:\n",
    "                # Pondere mai mare pentru potrivirile din câmpuri structurale\n",
    "                score += 8\n",
    "\n",
    "            # Verific și potriviri la nivel de cuvânt în aceste câmpuri\n",
    "            for word in label_info['words']:\n",
    "                if word in field_value:\n",
    "                    score += 3\n",
    "\n",
    "        return score\n",
    "\n",
    "    def classify_company(self, company, top_n=3):\n",
    "        \"\"\"\n",
    "        Clasific o companie în cele mai relevante etichete din taxonomia de asigurări.\n",
    "\n",
    "        Args:\n",
    "            company (dict): Datele companiei cu descriere, business_tags, sector, categorie, nișă\n",
    "            top_n (int): Numărul de potriviri de top de returnat\n",
    "\n",
    "        Returns:\n",
    "            dict: Rezultatele clasificării cu etichete potrivite și scoruri\n",
    "        \"\"\"\n",
    "        # Preprocesez datele companiei\n",
    "        processed_company = self._preprocess_company(company)\n",
    "\n",
    "        # Calculez scoruri pentru fiecare etichetă din taxonomie\n",
    "        scores = []\n",
    "        for idx, label_info in enumerate(self.processed_labels):\n",
    "            score = self._score_company_for_label(processed_company, label_info)\n",
    "            scores.append({\n",
    "                'label': label_info['original'],\n",
    "                'score': score\n",
    "            })\n",
    "\n",
    "        # Sortez după scor în ordine descrescătoare\n",
    "        sorted_scores = sorted(scores, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "        # Obțin primele N potriviri\n",
    "        top_matches = sorted_scores[:top_n]\n",
    "\n",
    "        # Filtrez potrivirile peste prag\n",
    "        matches_above_threshold = [\n",
    "            match for match in sorted_scores\n",
    "            if match['score'] >= self.threshold * 100  # Convertește pragul la aceeași scară ca scorurile\n",
    "        ]\n",
    "\n",
    "        # Mă asigur că returnez cel puțin o etichetă (cea mai bună potrivire)\n",
    "        if not matches_above_threshold:\n",
    "            matches_above_threshold = [sorted_scores[0]]\n",
    "\n",
    "        return {\n",
    "            'top_matches': top_matches,\n",
    "            'matches_above_threshold': matches_above_threshold\n",
    "        }\n",
    "\n",
    "    def classify_companies(self, companies_df):\n",
    "        \"\"\"\n",
    "        Clasific mai multe companii într-un DataFrame.\n",
    "\n",
    "        Args:\n",
    "            companies_df (DataFrame): DataFrame care conține datele companiilor\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: DataFrame-ul original cu coloana insurance_label adăugată\n",
    "        \"\"\"\n",
    "        # Creez o copie pentru a evita modificarea originalului\n",
    "        result_df = companies_df.copy()\n",
    "\n",
    "        # Adaug coloane pentru etichete de asigurare și scoruri de încredere\n",
    "        result_df['insurance_label'] = None\n",
    "        result_df['confidence_score'] = None\n",
    "\n",
    "        # Timp total de procesare și statistici\n",
    "        start_time = time.time()\n",
    "        total_companies = len(result_df)\n",
    "\n",
    "        print(f\"[{self._get_timestamp()}] Începerea clasificării pentru {total_companies} companii...\")\n",
    "\n",
    "        # Procesez fiecare companie\n",
    "        for idx, row in result_df.iterrows():\n",
    "            company_dict = row.to_dict()\n",
    "            classification = self.classify_company(company_dict)\n",
    "\n",
    "            # Obțin etichetele potrivite și scorurile\n",
    "            matched_items = classification['matches_above_threshold']\n",
    "            matched_labels = [match['label'] for match in matched_items]\n",
    "\n",
    "            # Unesc etichetele multiple cu punct și virgulă\n",
    "            result_df.at[idx, 'insurance_label'] = '; '.join(matched_labels)\n",
    "\n",
    "            # Adaug scorul de încredere (media scorurilor de top)\n",
    "            if matched_items:\n",
    "                avg_confidence = sum(match['score'] for match in matched_items) / len(matched_items)\n",
    "                result_df.at[idx, 'confidence_score'] = round(avg_confidence, 2)\n",
    "            else:\n",
    "                result_df.at[idx, 'confidence_score'] = 0\n",
    "\n",
    "            # Afișez progresul pentru fiecare 100 de companii\n",
    "            if idx % 100 == 0 or idx == total_companies - 1:\n",
    "                elapsed = time.time() - start_time\n",
    "                rate = (idx + 1) / elapsed if elapsed > 0 else 0\n",
    "                remaining = (total_companies - idx - 1) / rate if rate > 0 else 0\n",
    "\n",
    "                print(f\"[{self._get_timestamp()}] Procesate {idx+1}/{total_companies} companii \" +\n",
    "                     f\"({rate:.1f} companii/sec, est. {remaining/60:.1f} min rămase)\")\n",
    "\n",
    "        # Statistici finale\n",
    "        elapsed_time = time.time() - start_time\n",
    "        avg_rate = total_companies / elapsed_time\n",
    "\n",
    "        print(f\"[{self._get_timestamp()}] Clasificare finalizată în {elapsed_time:.1f} secunde!\")\n",
    "        print(f\"[{self._get_timestamp()}] Viteză medie de procesare: {avg_rate:.1f} companii/secundă\")\n",
    "\n",
    "        # Calculez statistici de etichete\n",
    "        unique_labels = set()\n",
    "        for labels in result_df['insurance_label'].str.split('; '):\n",
    "            unique_labels.update(labels)\n",
    "\n",
    "        multi_label_count = sum(result_df['insurance_label'].str.contains(';'))\n",
    "\n",
    "        print(f\"[{self._get_timestamp()}] Statistici finale:\")\n",
    "        print(f\"  - Etichete unice utilizate: {len(unique_labels)}/{len(self.taxonomy_labels)} ({len(unique_labels)/len(self.taxonomy_labels)*100:.1f}%)\")\n",
    "        print(f\"  - Companii cu etichete multiple: {multi_label_count} ({multi_label_count/total_companies*100:.1f}%)\")\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    def evaluate_performance(self, test_companies, sample_size=200):\n",
    "        \"\"\"\n",
    "        Evaluez performanța clasificatorului pe un eșantion de companii.\n",
    "\n",
    "        Args:\n",
    "            test_companies (DataFrame): Companiile pentru evaluare\n",
    "            sample_size (int): Numărul de companii de eșantionat\n",
    "\n",
    "        Returns:\n",
    "            dict: Metrici de performanță\n",
    "        \"\"\"\n",
    "        print(f\"[{self._get_timestamp()}] Evaluarea performanței pe un eșantion de {sample_size} companii...\")\n",
    "\n",
    "        if len(test_companies) > sample_size:\n",
    "            sample = test_companies.sample(sample_size, random_state=42)\n",
    "        else:\n",
    "            sample = test_companies\n",
    "\n",
    "        # Procesez eșantionul\n",
    "        results = []\n",
    "        start_time = time.time()\n",
    "\n",
    "        for idx, row in sample.iterrows():\n",
    "            company_dict = row.to_dict()\n",
    "            classification = self.classify_company(company_dict)\n",
    "\n",
    "            top_match = classification['top_matches'][0]\n",
    "            matches_count = len(classification['matches_above_threshold'])\n",
    "\n",
    "            results.append({\n",
    "                'company_idx': idx,\n",
    "                'sector': company_dict['sector'],\n",
    "                'category': company_dict['category'],\n",
    "                'top_match': top_match['label'],\n",
    "                'top_score': top_match['score'],\n",
    "                'matches_count': matches_count,\n",
    "                'all_matches': [match['label'] for match in classification['matches_above_threshold']]\n",
    "            })\n",
    "\n",
    "        # Calculez metricile de performanță\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        # Distribuția etichetelor\n",
    "        label_counts = results_df['top_match'].value_counts().to_dict()\n",
    "\n",
    "        # Numărul mediu de potriviri per companie\n",
    "        avg_matches = results_df['matches_count'].mean()\n",
    "\n",
    "        # Distribuția pe sectoare\n",
    "        sector_distribution = results_df.groupby('sector')['top_match'].apply(list).to_dict()\n",
    "\n",
    "        # Analizez diversitatea potrivirilor\n",
    "        all_match_labels = [label for matches in results_df['all_matches'] for label in matches]\n",
    "        unique_labels_assigned = len(set(all_match_labels))\n",
    "        label_coverage = unique_labels_assigned / len(self.taxonomy_labels) * 100\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        print(f\"[{self._get_timestamp()}] Evaluare finalizată în {elapsed_time:.2f} secunde\")\n",
    "        print(f\"[{self._get_timestamp()}] Rezultate evaluare:\")\n",
    "        print(f\"  - Număr mediu de potriviri per companie: {avg_matches:.2f}\")\n",
    "        print(f\"  - Etichete unice atribuite: {unique_labels_assigned} ({label_coverage:.1f}% din taxonomie)\")\n",
    "        print(f\"  - Top 5 etichete atribuite:\")\n",
    "\n",
    "        for label, count in sorted(label_counts.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "            print(f\"    - {label}: {count}\")\n",
    "\n",
    "        return {\n",
    "            'label_distribution': label_counts,\n",
    "            'avg_matches_per_company': avg_matches,\n",
    "            'sector_distribution': sector_distribution,\n",
    "            'unique_labels_assigned': unique_labels_assigned,\n",
    "            'label_coverage_percentage': label_coverage,\n",
    "            'sample_results': results\n",
    "        }\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Funcția principală pentru rularea clasificatorului.\"\"\"\n",
    "\n",
    "    # Calea către fișiere\n",
    "    taxonomy_path = \"insurance_taxonomy.csv\"\n",
    "    companies_path = \"ml_insurance_challenge.csv\"\n",
    "    output_path = \"annotated_companies1.csv\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"CLASIFICATOR DE TAXONOMIE PENTRU ASIGURĂRI\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Încarc datele\n",
    "    print(\"\\nÎncărcarea datelor...\")\n",
    "    start_time = time.time()\n",
    "    taxonomy_df = pd.read_csv(taxonomy_path)\n",
    "    companies_df = pd.read_csv(companies_path)\n",
    "    data_load_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Au fost încărcate {len(taxonomy_df)} etichete de taxonomie\")\n",
    "    print(f\"Au fost încărcate {len(companies_df)} companii\")\n",
    "    print(f\"Date încărcate în {data_load_time:.2f} secunde\")\n",
    "\n",
    "    # Inițializez clasificatorul\n",
    "    print(\"\\nInițializarea clasificatorului...\")\n",
    "    start_time = time.time()\n",
    "    classifier = InsuranceTaxonomyClassifier(\n",
    "        taxonomy_path=taxonomy_path,\n",
    "        threshold=0.15\n",
    "    )\n",
    "    init_time = time.time() - start_time\n",
    "    print(f\"Clasificator inițializat în {init_time:.2f} secunde\")\n",
    "\n",
    "    # Evalueaz pe un eșantion înainte de clasificarea completă\n",
    "    print(\"\\nEvaluarea performanței clasificatorului pe un eșantion...\")\n",
    "    evaluation = classifier.evaluate_performance(companies_df, sample_size=200)\n",
    "\n",
    "    # Clasific toate companiile\n",
    "    print(\"\\nClasificarea tuturor companiilor...\")\n",
    "    results_df = classifier.classify_companies(companies_df)\n",
    "\n",
    "    # Salvez rezultatele\n",
    "    print(f\"\\nSalvarea setului de date adnotat în {output_path}...\")\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(\"\\nProcesul de clasificare finalizat cu succes!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "a25dfe06682ef925",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CLASIFICATOR DE TAXONOMIE PENTRU ASIGURĂRI\n",
      "================================================================================\n",
      "\n",
      "Încărcarea datelor...\n",
      "Au fost încărcate 220 etichete de taxonomie\n",
      "Au fost încărcate 9494 companii\n",
      "Date încărcate în 0.07 secunde\n",
      "\n",
      "Inițializarea clasificatorului...\n",
      "[16:51:22] Inițializare clasificator...\n",
      "[16:51:22] Procesare 220 etichete din taxonomie...\n",
      "[16:51:22] Clasificator inițializat cu succes!\n",
      "Clasificator inițializat în 0.02 secunde\n",
      "\n",
      "Evaluarea performanței clasificatorului pe un eșantion...\n",
      "[16:51:22] Evaluarea performanței pe un eșantion de 200 companii...\n",
      "[16:51:54] Evaluare finalizată în 31.28 secunde\n",
      "[16:51:54] Rezultate evaluare:\n",
      "  - Număr mediu de potriviri per companie: 45.91\n",
      "  - Etichete unice atribuite: 217 (98.6% din taxonomie)\n",
      "  - Top 5 etichete atribuite:\n",
      "    - Fishing and Hunting Services: 44\n",
      "    - Oil and Fat Manufacturing: 42\n",
      "    - Training Services: 8\n",
      "    - Sand and Gravel Mining: 8\n",
      "    - Consulting Services: 7\n",
      "\n",
      "Clasificarea tuturor companiilor...\n",
      "[16:51:54] Începerea clasificării pentru 9494 companii...\n",
      "[16:51:54] Procesate 1/9494 companii (6.4 companii/sec, est. 24.6 min rămase)\n",
      "[16:52:09] Procesate 101/9494 companii (6.4 companii/sec, est. 24.6 min rămase)\n",
      "[16:52:26] Procesate 201/9494 companii (6.2 companii/sec, est. 24.9 min rămase)\n",
      "[16:52:42] Procesate 301/9494 companii (6.2 companii/sec, est. 24.6 min rămase)\n",
      "[16:52:58] Procesate 401/9494 companii (6.2 companii/sec, est. 24.3 min rămase)\n",
      "[16:53:14] Procesate 501/9494 companii (6.2 companii/sec, est. 24.1 min rămase)\n",
      "[16:53:30] Procesate 601/9494 companii (6.2 companii/sec, est. 23.9 min rămase)\n",
      "[16:53:46] Procesate 701/9494 companii (6.2 companii/sec, est. 23.6 min rămase)\n",
      "[16:54:03] Procesate 801/9494 companii (6.2 companii/sec, est. 23.4 min rămase)\n",
      "[16:54:18] Procesate 901/9494 companii (6.2 companii/sec, est. 23.0 min rămase)\n",
      "[16:54:34] Procesate 1001/9494 companii (6.2 companii/sec, est. 22.8 min rămase)\n",
      "[16:54:51] Procesate 1101/9494 companii (6.2 companii/sec, est. 22.5 min rămase)\n",
      "[16:55:07] Procesate 1201/9494 companii (6.2 companii/sec, est. 22.2 min rămase)\n",
      "[16:55:23] Procesate 1301/9494 companii (6.2 companii/sec, est. 22.0 min rămase)\n",
      "[16:55:39] Procesate 1401/9494 companii (6.2 companii/sec, est. 21.7 min rămase)\n",
      "[16:55:54] Procesate 1501/9494 companii (6.2 companii/sec, est. 21.4 min rămase)\n",
      "[16:56:10] Procesate 1601/9494 companii (6.2 companii/sec, est. 21.1 min rămase)\n",
      "[16:56:25] Procesate 1701/9494 companii (6.3 companii/sec, est. 20.8 min rămase)\n",
      "[16:56:41] Procesate 1801/9494 companii (6.3 companii/sec, est. 20.5 min rămase)\n",
      "[16:56:56] Procesate 1901/9494 companii (6.3 companii/sec, est. 20.1 min rămase)\n",
      "[16:57:12] Procesate 2001/9494 companii (6.3 companii/sec, est. 19.9 min rămase)\n",
      "[16:57:28] Procesate 2101/9494 companii (6.3 companii/sec, est. 19.6 min rămase)\n",
      "[16:57:44] Procesate 2201/9494 companii (6.3 companii/sec, est. 19.3 min rămase)\n",
      "[16:58:00] Procesate 2301/9494 companii (6.3 companii/sec, est. 19.1 min rămase)\n",
      "[16:58:17] Procesate 2401/9494 companii (6.3 companii/sec, est. 18.9 min rămase)\n",
      "[16:58:33] Procesate 2501/9494 companii (6.3 companii/sec, est. 18.6 min rămase)\n",
      "[16:58:49] Procesate 2601/9494 companii (6.3 companii/sec, est. 18.4 min rămase)\n",
      "[16:59:05] Procesate 2701/9494 companii (6.3 companii/sec, est. 18.1 min rămase)\n",
      "[16:59:21] Procesate 2801/9494 companii (6.3 companii/sec, est. 17.8 min rămase)\n",
      "[16:59:37] Procesate 2901/9494 companii (6.3 companii/sec, est. 17.5 min rămase)\n",
      "[16:59:53] Procesate 3001/9494 companii (6.3 companii/sec, est. 17.3 min rămase)\n",
      "[17:00:09] Procesate 3101/9494 companii (6.3 companii/sec, est. 17.0 min rămase)\n",
      "[17:00:25] Procesate 3201/9494 companii (6.3 companii/sec, est. 16.7 min rămase)\n",
      "[17:00:40] Procesate 3301/9494 companii (6.3 companii/sec, est. 16.5 min rămase)\n",
      "[17:00:57] Procesate 3401/9494 companii (6.3 companii/sec, est. 16.2 min rămase)\n",
      "[17:01:13] Procesate 3501/9494 companii (6.3 companii/sec, est. 16.0 min rămase)\n",
      "[17:01:30] Procesate 3601/9494 companii (6.2 companii/sec, est. 15.7 min rămase)\n",
      "[17:01:45] Procesate 3701/9494 companii (6.3 companii/sec, est. 15.4 min rămase)\n",
      "[17:02:01] Procesate 3801/9494 companii (6.3 companii/sec, est. 15.2 min rămase)\n",
      "[17:02:16] Procesate 3901/9494 companii (6.3 companii/sec, est. 14.9 min rămase)\n",
      "[17:02:32] Procesate 4001/9494 companii (6.3 companii/sec, est. 14.6 min rămase)\n",
      "[17:02:47] Procesate 4101/9494 companii (6.3 companii/sec, est. 14.3 min rămase)\n",
      "[17:03:03] Procesate 4201/9494 companii (6.3 companii/sec, est. 14.1 min rămase)\n",
      "[17:03:18] Procesate 4301/9494 companii (6.3 companii/sec, est. 13.8 min rămase)\n",
      "[17:03:34] Procesate 4401/9494 companii (6.3 companii/sec, est. 13.5 min rămase)\n",
      "[17:03:49] Procesate 4501/9494 companii (6.3 companii/sec, est. 13.2 min rămase)\n",
      "[17:04:08] Procesate 4601/9494 companii (6.3 companii/sec, est. 13.0 min rămase)\n",
      "[17:04:25] Procesate 4701/9494 companii (6.3 companii/sec, est. 12.8 min rămase)\n",
      "[17:04:44] Procesate 4801/9494 companii (6.2 companii/sec, est. 12.6 min rămase)\n",
      "[17:05:02] Procesate 4901/9494 companii (6.2 companii/sec, est. 12.3 min rămase)\n",
      "[17:05:20] Procesate 5001/9494 companii (6.2 companii/sec, est. 12.1 min rămase)\n",
      "[17:05:38] Procesate 5101/9494 companii (6.2 companii/sec, est. 11.8 min rămase)\n",
      "[17:05:56] Procesate 5201/9494 companii (6.2 companii/sec, est. 11.6 min rămase)\n",
      "[17:06:13] Procesate 5301/9494 companii (6.2 companii/sec, est. 11.3 min rămase)\n",
      "[17:06:28] Procesate 5401/9494 companii (6.2 companii/sec, est. 11.0 min rămase)\n",
      "[17:06:43] Procesate 5501/9494 companii (6.2 companii/sec, est. 10.8 min rămase)\n",
      "[17:06:58] Procesate 5601/9494 companii (6.2 companii/sec, est. 10.5 min rămase)\n",
      "[17:07:13] Procesate 5701/9494 companii (6.2 companii/sec, est. 10.2 min rămase)\n",
      "[17:07:29] Procesate 5801/9494 companii (6.2 companii/sec, est. 9.9 min rămase)\n",
      "[17:07:45] Procesate 5901/9494 companii (6.2 companii/sec, est. 9.7 min rămase)\n",
      "[17:08:00] Procesate 6001/9494 companii (6.2 companii/sec, est. 9.4 min rămase)\n",
      "[17:08:15] Procesate 6101/9494 companii (6.2 companii/sec, est. 9.1 min rămase)\n",
      "[17:08:31] Procesate 6201/9494 companii (6.2 companii/sec, est. 8.8 min rămase)\n",
      "[17:08:46] Procesate 6301/9494 companii (6.2 companii/sec, est. 8.5 min rămase)\n",
      "[17:09:01] Procesate 6401/9494 companii (6.2 companii/sec, est. 8.3 min rămase)\n",
      "[17:09:17] Procesate 6501/9494 companii (6.2 companii/sec, est. 8.0 min rămase)\n",
      "[17:09:33] Procesate 6601/9494 companii (6.2 companii/sec, est. 7.7 min rămase)\n",
      "[17:09:48] Procesate 6701/9494 companii (6.2 companii/sec, est. 7.5 min rămase)\n",
      "[17:10:04] Procesate 6801/9494 companii (6.2 companii/sec, est. 7.2 min rămase)\n",
      "[17:10:19] Procesate 6901/9494 companii (6.2 companii/sec, est. 6.9 min rămase)\n",
      "[17:10:34] Procesate 7001/9494 companii (6.2 companii/sec, est. 6.7 min rămase)\n",
      "[17:10:49] Procesate 7101/9494 companii (6.3 companii/sec, est. 6.4 min rămase)\n",
      "[17:11:05] Procesate 7201/9494 companii (6.3 companii/sec, est. 6.1 min rămase)\n",
      "[17:11:20] Procesate 7301/9494 companii (6.3 companii/sec, est. 5.8 min rămase)\n",
      "[17:11:35] Procesate 7401/9494 companii (6.3 companii/sec, est. 5.6 min rămase)\n",
      "[17:11:50] Procesate 7501/9494 companii (6.3 companii/sec, est. 5.3 min rămase)\n",
      "[17:12:05] Procesate 7601/9494 companii (6.3 companii/sec, est. 5.0 min rămase)\n",
      "[17:12:20] Procesate 7701/9494 companii (6.3 companii/sec, est. 4.8 min rămase)\n",
      "[17:12:35] Procesate 7801/9494 companii (6.3 companii/sec, est. 4.5 min rămase)\n",
      "[17:12:50] Procesate 7901/9494 companii (6.3 companii/sec, est. 4.2 min rămase)\n",
      "[17:13:05] Procesate 8001/9494 companii (6.3 companii/sec, est. 4.0 min rămase)\n",
      "[17:13:20] Procesate 8101/9494 companii (6.3 companii/sec, est. 3.7 min rămase)\n",
      "[17:13:36] Procesate 8201/9494 companii (6.3 companii/sec, est. 3.4 min rămase)\n",
      "[17:13:51] Procesate 8301/9494 companii (6.3 companii/sec, est. 3.2 min rămase)\n",
      "[17:14:07] Procesate 8401/9494 companii (6.3 companii/sec, est. 2.9 min rămase)\n",
      "[17:14:22] Procesate 8501/9494 companii (6.3 companii/sec, est. 2.6 min rămase)\n",
      "[17:14:38] Procesate 8601/9494 companii (6.3 companii/sec, est. 2.4 min rămase)\n",
      "[17:14:53] Procesate 8701/9494 companii (6.3 companii/sec, est. 2.1 min rămase)\n",
      "[17:15:08] Procesate 8801/9494 companii (6.3 companii/sec, est. 1.8 min rămase)\n",
      "[17:15:24] Procesate 8901/9494 companii (6.3 companii/sec, est. 1.6 min rămase)\n",
      "[17:15:39] Procesate 9001/9494 companii (6.3 companii/sec, est. 1.3 min rămase)\n",
      "[17:15:55] Procesate 9101/9494 companii (6.3 companii/sec, est. 1.0 min rămase)\n",
      "[17:16:10] Procesate 9201/9494 companii (6.3 companii/sec, est. 0.8 min rămase)\n",
      "[17:16:26] Procesate 9301/9494 companii (6.3 companii/sec, est. 0.5 min rămase)\n",
      "[17:16:41] Procesate 9401/9494 companii (6.3 companii/sec, est. 0.2 min rămase)\n",
      "[17:16:56] Procesate 9494/9494 companii (6.3 companii/sec, est. 0.0 min rămase)\n",
      "[17:16:56] Clasificare finalizată în 1502.4 secunde!\n",
      "[17:16:56] Viteză medie de procesare: 6.3 companii/secundă\n",
      "[17:16:56] Statistici finale:\n",
      "  - Etichete unice utilizate: 220/220 (100.0%)\n",
      "  - Companii cu etichete multiple: 9458 (99.6%)\n",
      "\n",
      "Salvarea setului de date adnotat în annotated_companies1.csv...\n",
      "\n",
      "Procesul de clasificare finalizat cu succes!\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:16:56.831126Z",
     "start_time": "2025-03-31T14:16:56.829209Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4889ed700222b396",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
